{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bc66581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, callbacks, optimizers, regularizers\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24adce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../outputs/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "MODEL_DIR = os.path.join(OUTPUT_DIR, \"models\")\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "SUBMISSION_DIR = os.path.join(OUTPUT_DIR, \"submissions\")\n",
    "os.makedirs(SUBMISSION_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e56f3334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (801, 22), Val shape: (90, 22)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "PROCESSED_DATA_DIR = \"../data/processed/\"\n",
    "train_df = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, \"train_processed.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, \"test_processed.csv\"))\n",
    "\n",
    "# Separate target\n",
    "y = train_df[\"Survived\"]\n",
    "X = train_df.drop(columns=[\"Survived\", \"PassengerId\"])\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}\")\n",
    "scaler = StandardScaler()\n",
    "num_features = ['Age', 'Fare', 'FamilySize']\n",
    "\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_val[num_features] = scaler.transform(X_val[num_features])\n",
    "test_df[num_features] = scaler.transform(test_df[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2de0f942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     |   Pclass |        Age |   SibSp |   Parch |        Fare |   FamilySize |   IsAlone |   HasCabin | Sex_male   | Embarked_Q   | Embarked_S   | Title_Miss   | Title_Mr   | Title_Mrs   | Title_Rare   | Cabin_deck_B   | Cabin_deck_C   | Cabin_deck_D   | Cabin_deck_E   | Cabin_deck_F   | Cabin_deck_G   | Cabin_deck_T   |\n",
      "|----:|---------:|-----------:|--------:|--------:|------------:|-------------:|----------:|-----------:|:-----------|:-------------|:-------------|:-------------|:-----------|:------------|:-------------|:---------------|:---------------|:---------------|:---------------|:---------------|:---------------|:---------------|\n",
      "|  86 |        3 | -1.00223   |       1 |       3 |  0.051433   |    1.9028    |         0 |          0 | True       | False        | True         | False        | True       | False       | False        | False          | False          | False          | False          | True           | False          | False          |\n",
      "| 329 |        1 | -1.00223   |       0 |       1 |  0.546842   |    0.0531123 |         0 |          1 | False      | False        | False        | True         | False      | False       | False        | True           | False          | False          | False          | False          | False          | False          |\n",
      "| 517 |        3 |  0.0487661 |       0 |       0 | -0.163171   |   -0.563452  |         1 |          0 | True       | True         | False        | False        | True       | False       | False        | False          | False          | False          | False          | True           | False          | False          |\n",
      "| 844 |        3 | -0.927156  |       0 |       0 | -0.488225   |   -0.563452  |         1 |          0 | True       | False        | True         | False        | True       | False       | False        | False          | False          | False          | False          | True           | False          | False          |\n",
      "| 408 |        3 | -0.626872  |       0 |       0 | -0.506852   |   -0.563452  |         1 |          0 | True       | False        | True         | False        | True       | False       | False        | False          | False          | False          | False          | True           | False          | False          |\n",
      "|  92 |        1 |  1.2499    |       1 |       0 |  0.613916   |    0.0531123 |         0 |          1 | True       | False        | True         | False        | True       | False       | False        | False          | False          | False          | True           | False          | False          | False          |\n",
      "| 625 |        1 |  2.37597   |       0 |       0 |  0.00831914 |   -0.563452  |         1 |          1 | True       | False        | True         | False        | True       | False       | False        | False          | False          | True           | False          | False          | False          | False          |\n",
      "| 496 |        1 |  1.85047   |       1 |       0 |  0.972639   |    0.0531123 |         0 |          1 | False      | False        | False        | True         | False      | False       | False        | False          | False          | True           | False          | False          | False          | False          |\n",
      "| 652 |        3 | -0.626872  |       0 |       0 | -0.493036   |   -0.563452  |         1 |          0 | True       | False        | True         | False        | True       | False       | False        | False          | False          | False          | False          | True           | False          | False          |\n",
      "| 318 |        1 |  0.123837  |       0 |       2 |  2.79021    |    0.669676  |         0 |          1 | False      | False        | True         | True         | False      | False       | False        | False          | True           | False          | False          | False          | False          | False          |\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "efecedda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "X_val = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
    "y_val = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "passenger_ids = test_df[\"PassengerId\"]\n",
    "X_test = tf.convert_to_tensor(test_df.drop(columns=[\"PassengerId\",\"Survived\"]), dtype=tf.float32)\n",
    "\n",
    "# --- Build DNN Model (Functional API) ---\n",
    "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "x = layers.Dense(128, activation='relu',name='l1',kernel_regularizer=regularizers.l2(0.001))(inputs)\n",
    "x = layers.Dropout(0.2,name='l1_dropout')(x)\n",
    "x = layers.Dense(32, activation='relu',name='l2',kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(0.1,name='l2_dropout')(x)\n",
    "x = layers.Dense(16, activation='relu',name='l3',kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.Dropout(0.1,name='l3_dropout')(x)\n",
    "x = layers.Dense(8, activation='relu',name='l4')(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid',name='output')(x)\n",
    "\n",
    "model = models.Model(inputs, outputs, name=\"DNN_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daf7527b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DNN_Model\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ input_layer_4 (InputLayer)      │ (None, 22)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ l1 (Dense)                      │ (None, 128)            │         2,944 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ l1_dropout (Dropout)            │ (None, 128)            │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ l2 (Dense)                      │ (None, 32)             │         4,128 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ l2_dropout (Dropout)            │ (None, 32)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ l3 (Dense)                      │ (None, 16)             │           528 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ l3_dropout (Dropout)            │ (None, 16)             │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ l4 (Dense)                      │ (None, 8)              │           136 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ output (Dense)                  │ (None, 1)              │             9 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 7,745 (30.25 KB)\n",
      " Trainable params: 7,745 (30.25 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.summary(print_fn=lambda x: print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2f06140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing model weights.\n"
     ]
    }
   ],
   "source": [
    "initial_lr = 0.001\n",
    "optimizer = optimizers.Adam(learning_rate=initial_lr)\n",
    "\n",
    "# Define LR scheduler (reduce when plateau)\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.7,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=35,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "if os.path.exists(os.path.join(MODEL_DIR, f\"{model.name.replace(' ', '_')}.keras\")):\n",
    "    model= keras.models.load_model(os.path.join(MODEL_DIR, f\"{model.name.replace(' ', '_')}.keras\"))\n",
    "    print(\"Loaded existing model weights.\")\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "else:\n",
    "    print(\"No existing model weights found, starting fresh.\")\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=[lr_scheduler, early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1f79b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(MODEL_DIR, f\"{model.name.replace(' ', '_')}.keras\")):\n",
    "    model.save(os.path.join(MODEL_DIR, f\"{model.name.replace(' ', '_')}.keras\"))\n",
    "    print(f\"Saved model for {model.name}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "275e9753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracy: 0.7889\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluate on Validation Set ---\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"\\nValidation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8aa0d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Submission file saved to: ../outputs/submissions\\DNN_Model_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Predict on Test Data ---\n",
    "test_preds = model.predict(X_test, verbose=1)\n",
    "test_preds = (test_preds > 0.5).astype(int).flatten()  # Convert sigmoid outputs to 0/1\n",
    "\n",
    "# --- Create Submission DataFrame ---\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": passenger_ids,\n",
    "    \"Survived\": test_preds\n",
    "})\n",
    "\n",
    "# --- Save submission file ---\n",
    "submission_path = os.path.join(SUBMISSION_DIR, f\"{model.name}_submission.csv\")\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission file saved to: {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-practice-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
